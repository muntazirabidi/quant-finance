# Question

To show that $G(a) \geq \sigma^2$ for all $a$ and determine the value of $a$ for which equality holds, we start by expanding $G(a)$:

$$
G(a) = E[(X - a)^2]
$$

Expanding the square and taking the expectation, we get:

$$
G(a) = E[X^2] - 2aE[X] + a^2
$$

Using the fact that $E[X] = \mu$ and $\text{Var}(X) = E[X^2] - \mu^2$, we substitute $E[X^2] = \sigma^2 + \mu^2$:

$$
G(a) = \sigma^2 + \mu^2 - 2a\mu + a^2
$$

This is a quadratic function in $a$:

$$
G(a) = a^2 - 2a\mu + (\mu^2 + \sigma^2)
$$

The minimum value of this quadratic function occurs at $a = \mu$. Substituting $a = \mu$ into $G(a)$:

$$
G(\mu) = E[(X - \mu)^2] = \sigma^2
$$

Thus, $G(a) \geq \sigma^2$ for all $a$, with equality when $a = \mu$.

For $H(a) = E[|X - a|]$, we express it in terms of the probability density function $f$:

$$
H(a) = \int_{-\infty}^{\infty} |x - a| f(x) \, dx
$$

Splitting the integral at $a$:

$$
H(a) = \int_{-\infty}^a (a - x) f(x) \, dx + \int_a^\infty (x - a) f(x) \, dx
$$

To find the value of $a$ that minimizes $H(a)$, we differentiate with respect to $a$:

$$
\frac{dH}{da} = \int_{-\infty}^a f(x) \, dx - \int_a^\infty f(x) \, dx
$$

Setting the derivative equal to zero:

$$
\int_{-\infty}^a f(x) \, dx = \int_a^\infty f(x) \, dx
$$

Since the total integral of $f(x)$is 1, this implies:

$$
\int_{-\infty}^a f(x) \, dx = \frac{1}{2}
$$

Thus, $H(a)$ is minimized when $a$ is the median of the distribution, satisfying $\int_{-\infty}^a f(x) \, dx = \frac{1}{2}$.

### Final Answer

For $G(a)$, equality holds when $a = \boxed{\mu}$. For $H(a)$, the minimizer $a$ satisfies $\int_{-\infty}^{a} f(x) \, dx = \frac{1}{2}$, so the answer is $ \boxed{\text{the median}}$.

# Question

- (a) Let $U$ and $V$ be two bounded random variables such that $E[U^k] = E[V^k]$ for all
  non-negative integers $k$. Show that $U$ and $V$ have the same moment generating function.

- (b) Let $X$ be a continuous random variable with probability density function
  $$
  f(x) = A e^{-x^2/2}
  $$
  for all real $x$, where A is a normalising constant. Compute the moment generating function of $X$.

## Solution part a:

To show that $U$ and $V$ have the same moment generating function (MGF) given that their moments are equal, we proceed as follows:

**Step 1: Definition of MGF**  
The MGF of a random variable $X$ is defined as:

$$
M_X(t) = \mathbb{E}[e^{tX}].
$$

**Step 2: Taylor Series Expansion**  
Expand $e^{tX}$ as a power series:

$$
e^{tX} = \sum_{k=0}^{\infty} \frac{(tX)^k}{k!}.
$$

**Step 3: Linearity of Expectation**  
Take the expectation of both sides:

$$
\mathbb{E}[e^{tX}] = \mathbb{E}\left[\sum_{k=0}^{\infty} \frac{(tX)^k}{k!}\right].
$$

**Step 4: Interchange Expectation and Summation**  
Since $U$ and $V$ are bounded (say $|X| \leq C$ for $X = U$ or $V$), the series $\sum_{k=0}^{\infty} \frac{|tX|^k}{k!}$ is dominated by $e^{|t|C}$, which is integrable. By the Dominated Convergence Theorem:

$$
\mathbb{E}\left[\sum_{k=0}^{\infty} \frac{(tX)^k}{k!}\right] = \sum_{k=0}^{\infty} \frac{t^k \mathbb{E}[X^k]}{k!}.
$$

**Step 5: Equality of Moments**  
Given $\mathbb{E}[U^k] = \mathbb{E}[V^k]$ for all $k \geq 0$, substitute into the series:

$$
M_U(t) = \sum_{k=0}^{\infty} \frac{t^k \mathbb{E}[U^k]}{k!} = \sum_{k=0}^{\infty} \frac{t^k \mathbb{E}[V^k]}{k!} = M_V(t).
$$

**Conclusion**  
Thus, $U$ and $V$ have the same moment generating function.  
$\boxed{M_U(t) = M_V(t) \text{ for all } t \in \mathbb{R}}$

## Solution part b:

To compute the moment generating function (MGF) of the random variable $X$ with density $f(x) = A e^{-x^2/2}$, follow these steps:

**Step 1: Determine the Normalizing Constant $A$**  
The density must satisfy $\int\_{-\infty}^\infty f(x) \, dx = 1$. Using the Gaussian integral:

$$
\int_{-\infty}^\infty e^{-x^2/2} \, dx = \sqrt{2\pi}.
$$

Thus, $A = \frac{1}{\sqrt{2\pi}}$.

**Step 2: Define the MGF**  
The MGF is given by:

$$
M_X(t) = \mathbb{E}[e^{tX}] = \int_{-\infty}^\infty e^{tx} f(x) \, dx = A \int_{-\infty}^\infty e^{tx - x^2/2} \, dx.
$$

**Step 3: Complete the Square in the Exponent**  
Rewrite the exponent:

$$
tx - \frac{x^2}{2} = -\frac{x^2 - 2tx}{2} = -\frac{(x - t)^2 - t^2}{2} = \frac{t^2}{2} - \frac{(x - t)^2}{2}.
$$

Substitute back into the integral:

$$
M_X(t) = A e^{t^2/2} \int_{-\infty}^\infty e^{-(x - t)^2/2} \, dx.
$$

**Step 4: Evaluate the Gaussian Integral**  
The integral $\int\_{-\infty}^\infty e^{-(x - t)^2/2} \, dx$ equals $\sqrt{2\pi}$ (shift does not affect the value). Thus:

$$
M_X(t) = A e^{t^2/2} \cdot \sqrt{2\pi}.
$$

**Step 5: Substitute $A = \frac{1}{\sqrt{2\pi}}$**  
Simplify:

$$
M_X(t) = \frac{1}{\sqrt{2\pi}} \cdot e^{t^2/2} \cdot \sqrt{2\pi} = e^{t^2/2}.
$$

**Final Answer**  
The moment generating function of $X$ is:

$$
\boxed{M_X(t) = e^{t^2/2}}.
$$
